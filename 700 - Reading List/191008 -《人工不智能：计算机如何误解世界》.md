# 人工不智能：计算机如何误解世界

## 书籍信息

- 作者梅瑞狄斯·布鲁萨德，毕业于哈佛大学计算机系，拥有计算机和数学的学位。
- 人工智能相关报道太多，很多都不切实际，这样很容易形成迷思。
- 人工智能远没有那么厉害，可以预见的时期内不会替代人类导致完全失业。

## 核心观点

- 高估人工智能会产生什么样的社会问题？
  - 比尔·盖茨和梅琳达基金会一直在美国全国推行一个所谓“共同核心课程”系统，相当于中国那种全国统一的教学大纲和标准化考试，但是在各地受到了老师和学校的抵抗。其实老师的抵抗有道理，这不仅仅是不民主，而是不同学区的学生水平差异很大，用同一个标准确实不合理。学校教学没有自由度，而且应试教育的负面影响太大，结果现在美国的公共教育非常混乱。
  - 布鲁萨德说，盖茨等人是想把教育当成一个工程问题去解决。**工程问题本质上是数学，需要在一个定义良好的环境里，用定义良好的参数描写一个定义良好的问题。**可是教育问题从来都不是“定义良好的，其中有各种复杂的情况。复杂和标准化是一对永恒的矛盾，这就是为什么计算机技术发展了这么多年，美国基础教育几乎没有发生任何进步。
- 自动驾驶这件事到底有多难？
  - 现阶段所有的人工智能，都有一个根本的弱点。这个弱点就是它们高度依赖数据，都是对过去经验的总结，它们没有办法预测“没见过”的事情。所以这种人工智能的应用非常有限。它最适合常见的、简单的、不变的应用场景，不能直接推广。一旦遭遇必须推广的场景，就面临各种问题，比如“自动驾驶汽车”。
  - 自动驾驶具有一定的安全问题。
  - 自动驾驶还具有一定的道德问题。
  - 自动驾驶技术还有一个经济学问题。机器学习是高度依赖数据的。我们知道有个“二八法则”，说的是你花20%的时间就能解决80%的问题，剩下80%的时间解决20%的问题。对自动驾驶汽车来说，我看更可能是你用2%的数据就能训练一个能解决路面80%的情况的自动驾驶系统，但是剩下那20%的情况，你就是再用98%的数据也未必能解决。
  - 即便是在“自动驾驶”这样看上去几乎纯工程领域的问题上，人工智能也有非常大的局限。第一，它不安全。第二，它不道德。第三，它不能促进商业平等，它只会让强大的公司变得更加强大。因此，在可以预见的未来，也许我们还是得自己开车。
- 现阶段人工智能的社会化应用的根本矛盾是什么？
  - 人工智能社会化应用的矛盾点在于一切基于经验的决策的本质缺陷。
  - 人工智能再厉害，只要是基于经验的，只要预测不是100%准确，就一定会有人被冤枉。所谓“公平”，其实是你的主观选择。选择算法准确度的公平，你就会冤枉一些特定的黑人；选择不冤枉黑人，你的算法就不准确，你就会冤枉别的人。算法可以根本不考虑种族，但种族就隐藏在数据之中。丑小鸭定理说，一切分类都是主观的。有分类就会有歧视，此事古难全。人工智能能给我们的决策提供很大的方便，但社会还是这个社会，数学还是同样的数学，人工智能改变不了问题的本质。

## 总结与收获

- 人工智能解决不了社会问题，社会问题的复杂性太高，而且不易于量化。
- 人工智能正在解决越来越多的工程问题，但是人工智能是基于经验迁移的，有一定的弊端。
- 不要害怕被人工智能替代，要在这个学科或者产业发展中贡献一份力量，这也是要读博士的原因。



